{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this project, you will build a neural network of your own design to evaluate the MNIST dataset.\n",
    "\n",
    "Some of the benchmark results on MNIST include can be found [on Yann LeCun's page](https://webcache.googleusercontent.com/search?q=cache:stAVPik6onEJ:yann.lecun.com/exdb/mnist) and include:\n",
    "\n",
    "88% [Lecun et al., 1998](https://hal.science/hal-03926082/document)\n",
    "\n",
    "95.3% [Lecun et al., 1998](https://hal.science/hal-03926082v1/document)\n",
    "\n",
    "99.65% [Ciresan et al., 2011](http://people.idsia.ch/~juergen/ijcai2011.pdf)\n",
    "\n",
    "\n",
    "MNIST is a great dataset for sanity checking your models, since the accuracy levels achieved by large convolutional neural networks and small linear models are both quite high. This makes it important to be familiar with the data.\n",
    "\n",
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the PATH to include the user installation directory. \n",
    "import os\n",
    "os.environ['PATH'] = f\"{os.environ['PATH']}:/root/.local/bin\"\n",
    "\n",
    "# Restart the Kernel before you move on to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important: Restart the Kernel before you move on to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python-headless==4.5.3.56\n",
      "  Downloading opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 37.1 MB 862 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib==3.4.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (3.4.3)\n",
      "Requirement already satisfied: numpy==1.21.2 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (1.21.2)\n",
      "Requirement already satisfied: pillow==7.0.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (7.0.0)\n",
      "Collecting bokeh==2.1.1\n",
      "  Downloading bokeh-2.1.1.tar.gz (19.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.3 MB 53.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch==1.11.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (1.11.0)\n",
      "Collecting torchvision==0.12.0\n",
      "  Downloading torchvision-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.0 MB 64.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm==4.63.0\n",
      "  Downloading tqdm-4.63.0-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 6.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting ipywidgets==7.7.0\n",
      "  Downloading ipywidgets-7.7.0-py2.py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 70.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting livelossplot==0.5.4\n",
      "  Downloading livelossplot-0.5.4-py3-none-any.whl (22 kB)\n",
      "Collecting pytest==7.1.1\n",
      "  Downloading pytest-7.1.1-py3-none-any.whl (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 71.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas==1.3.5\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 62.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting seaborn==0.11.2\n",
      "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[K     |████████████████████████████████| 292 kB 62.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter==1.0.0\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Collecting ipykernel==4.10.0\n",
      "  Downloading ipykernel-4.10.0-py3-none-any.whl (109 kB)\n",
      "\u001b[K     |████████████████████████████████| 109 kB 68.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 2)) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 2)) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 2)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.1.1->-r requirements.txt (line 5)) (5.3)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.1.1->-r requirements.txt (line 5)) (2.11.1)\n",
      "Requirement already satisfied: packaging>=16.8 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.1.1->-r requirements.txt (line 5)) (20.1)\n",
      "Requirement already satisfied: tornado>=5.1 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.1.1->-r requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: typing_extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.1.1->-r requirements.txt (line 5)) (3.7.4.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision==0.12.0->-r requirements.txt (line 7)) (2.23.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.2.0)\n",
      "Collecting jupyterlab-widgets>=1.0.0; python_version >= \"3.6\"\n",
      "  Downloading jupyterlab_widgets-3.0.11-py3-none-any.whl (214 kB)\n",
      "\u001b[K     |████████████████████████████████| 214 kB 74.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets==7.7.0->-r requirements.txt (line 9)) (4.3.3)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets==7.7.0->-r requirements.txt (line 9)) (5.0.4)\n",
      "Collecting widgetsnbextension~=3.6.0\n",
      "  Downloading widgetsnbextension-3.6.6-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 58.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /opt/conda/lib/python3.7/site-packages (from ipywidgets==7.7.0->-r requirements.txt (line 9)) (7.13.0)\n",
      "Collecting iniconfig\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Collecting pluggy<2.0,>=0.12\n",
      "  Downloading pluggy-1.2.0-py3-none-any.whl (17 kB)\n",
      "Collecting py>=1.8.2\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from pytest==7.1.1->-r requirements.txt (line 11)) (1.5.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.7/site-packages (from pytest==7.1.1->-r requirements.txt (line 11)) (19.3.0)\n",
      "Collecting tomli>=1.0.0\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas==1.3.5->-r requirements.txt (line 12)) (2019.3)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.7/site-packages (from seaborn==0.11.2->-r requirements.txt (line 13)) (1.7.1)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from jupyter==1.0.0->-r requirements.txt (line 14)) (5.6.1)\n",
      "Collecting jupyter-console\n",
      "  Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.7/site-packages (from jupyter==1.0.0->-r requirements.txt (line 14)) (5.7.4)\n",
      "Collecting qtconsole\n",
      "  Downloading qtconsole-5.4.4-py3-none-any.whl (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 68.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jupyter-client in /opt/conda/lib/python3.7/site-packages (from ipykernel==4.10.0->-r requirements.txt (line 15)) (6.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib==3.4.3->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib==3.4.3->-r requirements.txt (line 2)) (45.2.0.post20200209)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=2.7->bokeh==2.1.1->-r requirements.txt (line 5)) (1.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 7)) (2019.11.28)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 7)) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 7)) (1.25.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 7)) (2.9)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets==7.7.0->-r requirements.txt (line 9)) (4.4.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets==7.7.0->-r requirements.txt (line 9)) (3.2.0)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets==7.7.0->-r requirements.txt (line 9)) (4.6.3)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (2.5.2)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.16.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.7.5)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.1.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (3.0.3)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (4.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest==7.1.1->-r requirements.txt (line 11)) (3.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 14)) (3.1.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 14)) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 14)) (1.4.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 14)) (0.3)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 14)) (0.4.4)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 14)) (0.6.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.7/site-packages (from jupyter-console->jupyter==1.0.0->-r requirements.txt (line 14)) (19.0.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 14)) (0.8.3)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 14)) (0.7.1)\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 14)) (1.5.0)\n",
      "Collecting qtpy>=2.4.0\n",
      "  Downloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[K     |████████████████████████████████| 93 kB 2.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.15.7)\n",
      "Requirement already satisfied: parso>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.6.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.1.8)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.6.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 14)) (0.5.1)\n",
      "Building wheels for collected packages: bokeh\n",
      "  Building wheel for bokeh (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bokeh: filename=bokeh-2.1.1-py3-none-any.whl size=9257186 sha256=512c2f51995855b83c3f5dfeed53376c5cdf0ffb1651493b09c22dc82813aa00\n",
      "  Stored in directory: /root/.cache/pip/wheels/f7/55/ff/f3d7554e69382d31cf7ad857cf518af9b923134fca7d925187\n",
      "Successfully built bokeh\n",
      "\u001b[31mERROR: jupyter-console 6.6.3 has requirement ipykernel>=6.14, but you'll have ipykernel 4.10.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyter-console 6.6.3 has requirement jupyter-client>=7.0.0, but you'll have jupyter-client 6.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyter-console 6.6.3 has requirement jupyter-core!=5.0.*,>=4.12, but you'll have jupyter-core 4.6.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyter-console 6.6.3 has requirement prompt-toolkit>=3.0.30, but you'll have prompt-toolkit 3.0.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyter-console 6.6.3 has requirement traitlets>=5.4, but you'll have traitlets 4.3.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: opencv-python-headless, bokeh, torchvision, tqdm, jupyterlab-widgets, ipykernel, widgetsnbextension, ipywidgets, livelossplot, iniconfig, pluggy, py, tomli, pytest, pandas, seaborn, jupyter-console, qtpy, qtconsole, jupyter\n",
      "\u001b[33m  WARNING: The script bokeh is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts py.test and pytest are installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script jupyter-console is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script qtpy is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed bokeh-2.1.1 iniconfig-2.0.0 ipykernel-4.10.0 ipywidgets-7.7.0 jupyter-1.0.0 jupyter-console-6.6.3 jupyterlab-widgets-3.0.11 livelossplot-0.5.4 opencv-python-headless-4.5.3.56 pandas-1.3.5 pluggy-1.2.0 py-1.11.0 pytest-7.1.1 qtconsole-5.4.4 qtpy-2.4.1 seaborn-0.11.2 tomli-2.0.1 torchvision-0.12.0 tqdm-4.63.0 widgetsnbextension-3.6.6\n"
     ]
    }
   ],
   "source": [
    "# Install requirements\n",
    "!python -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell contains the essential imports you will need – DO NOT CHANGE THE CONTENTS! ##\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "Specify your transforms as a list if you intend to .\n",
    "The transforms module is already loaded as `transforms`.\n",
    "\n",
    "MNIST is fortunately included in the torchvision module.\n",
    "Then, you can create your dataset using the `MNIST` object from `torchvision.datasets` ([the documentation is available here](https://pytorch.org/vision/stable/datasets.html#mnist)).\n",
    "Make sure to specify `download=True`! \n",
    "\n",
    "Once your dataset is created, you'll also need to define a `DataLoader` from the `torch.utils.data` module for both the train and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "FloatProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIProgress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# No total? Show info style bar with no progress tqdm status\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'IProgress' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6fc069afe3c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Create training set and define training dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# I'll name my training set, 'train_data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m                         \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                         \u001b[0mmd5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmd5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m                     )\n\u001b[1;32m    181\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m     \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloading '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0m_urlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'https'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUSER_AGENT\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0munit_scale\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         self.container = self.status_printer(\n\u001b[0;32m--> 209\u001b[0;31m             self.fp, total, self.desc, self.ncols)\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m# #187 #451 #558\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             raise ImportError(\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0;34m\"FloatProgress not found. Please update jupyter and ipywidgets.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                 \u001b[0;34m\" See https://ipywidgets.readthedocs.io/en/stable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \"/user_install.html\")\n",
      "\u001b[0;31mImportError\u001b[0m: FloatProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "# Doing our required importations for the data loader of our dataset first,\n",
    "from torch.utils.data import DataLoader\n",
    "# Define transforms\n",
    "def create_transform():\n",
    "    \"\"\"\"\n",
    "    Here, we'll define our transformation, using torch.nn.Sequential\n",
    "    It will return a PyTorch transformation object.\n",
    "    \"\"\"\n",
    "    return torch.nn.Sequential(torch.nn.ToTensor)\n",
    "\n",
    "# Create training set and define training dataloader\n",
    "# I'll name my training set, 'train_data'\n",
    "train_data = torchvision.datasets.MNIST(download=True, root='data', train=True, transform=create_transform)\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=64)\n",
    "\n",
    "# Create test set and define test dataloader\n",
    "transform = create_transform\n",
    "# Now I'll personally define my test set as test_data\n",
    "test_data = torchvision.datasets.MNIST(root='data', download=True, train=False, transform=create_transform)\n",
    "test_loader = Dataloader(dataset=test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justify your preprocessing\n",
    "\n",
    "In your own words, why did you choose the transforms you chose? If you didn't use any preprocessing steps, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DOUBLE CLICK THIS CELL TO MODIFY**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Dataset\n",
    "Using matplotlib, numpy, and torch, explore the dimensions of your data.\n",
    "\n",
    "You can view images using the `show5` function defined below – it takes a data loader as an argument.\n",
    "Remember that normalized images will look really weird to you! You may want to try changing your transforms to view images.\n",
    "Typically using no transforms other than `toTensor()` works well for viewing – but not as well for training your network.\n",
    "If `show5` doesn't work, go back and check your code for creating your data loaders and your training/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell contains a function for showing 5 images from a dataloader – DO NOT CHANGE THE CONTENTS! ##\n",
    "def show5(img_loader):\n",
    "    dataiter = iter(img_loader)\n",
    "    \n",
    "    batch = next(dataiter)\n",
    "    labels = batch[1][0:5]\n",
    "    images = batch[0][0:5]\n",
    "    for i in range(5):\n",
    "        print(int(labels[i].detach()))\n",
    "    \n",
    "        image = images[i].numpy()\n",
    "        plt.imshow(image.T.squeeze().T)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b199413d15e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Explore data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Size of the training set:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Size of the test set:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape of training set:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape of test set:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Explore data\n",
    "print(\"Size of the training set:\", len(train_data))\n",
    "print(\"Size of the test set:\", len(test_data))\n",
    "print(\"Shape of training set:\", train_data[0][0].shape)\n",
    "print(\"Shape of test set:\", test_data[0][0].shape)\n",
    "show5(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your Neural Network\n",
    "Using the layers in `torch.nn` (which has been imported as `nn`) and the `torch.nn.functional` module (imported as `F`), construct a neural network based on the parameters of the dataset.\n",
    "Use any architecture you like. \n",
    "\n",
    "*Note*: If you did not flatten your tensors in your transforms or as part of your preprocessing and you are using only `Linear` layers, make sure to use the `Flatten` layer in your network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        # Now representing our linear layer in the neural network with two arguments the input and output size,\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify a loss function and an optimizer, and instantiate the model.\n",
    "\n",
    "If you use a less common loss function, please note why you chose that loss function in a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9890b449fe3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'eta' is not defined"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=eta, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running your Neural Network\n",
    "Use whatever method you like to train your neural network, and ensure you record the average loss at each epoch. \n",
    "Don't forget to use `torch.device()` and the `.to()` method for both your model and your data if you are using GPU!\n",
    "\n",
    "If you want to print your loss **during** each epoch, you can use the `enumerate` function and print the loss after a set number of batches. 250 batches works well for most people!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-214f7cf1f507>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Extract images and labels from the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assuming data is a tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Defining the device to use (cuda if available, cpu otherwise)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the chosen device\n",
    "model.to(device)\n",
    "\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "# Define the number of batches to print the loss\n",
    "print_loss_every = 250\n",
    "\n",
    "# Lists to store the loss values\n",
    "train_loss_values = []\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 20\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        # Extract images and labels from the data\n",
    "        images, labels = data[0].to(device), data[1].to(device)  # Assuming data is a tuple\n",
    "\n",
    "        # Clear gradients before each pass\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Print loss every few batches\n",
    "        if (batch_idx + 1) % print_loss_every == 0:\n",
    "            avg_loss = running_loss / print_loss_every\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {avg_loss:.4f}\")\n",
    "            train_loss_values.append(avg_loss)\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training loss (and validation loss/accuracy, if recorded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the training loss now,\n",
    "plt.plot(train_loss_values)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your model\n",
    "Using the previously created `DataLoader` for the test set, compute the percentage of correct predictions using the highest probability prediction. \n",
    "\n",
    "If your accuracy is over 90%, great work, but see if you can push a bit further! \n",
    "If your accuracy is under 90%, you'll need to make improvements.\n",
    "Go back and check your model architecture, loss function, and optimizer to make sure they're appropriate for an image classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4a918f1471a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Looping through the test data loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Switched order of labels and images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Move data to the appropriate device (GPU/CPU)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's initialize counters for tracking accuracy\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "# Setting the model to evaluation mode (disable dropout etc.)\n",
    "model.eval()\n",
    "\n",
    "# Looping through the test data loader\n",
    "for labels, images in test_loader:  # Switched order of labels and images\n",
    "    # Move data to the appropriate device (GPU/CPU)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # Make predictions using the model\n",
    "    outputs = model(images)\n",
    "\n",
    "    # Get the predicted class with the highest probability\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    # Update correct predictions based on matches with labels\n",
    "    correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    # Update total predictions based on batch size\n",
    "    total_predictions += labels.size(0)\n",
    "\n",
    "# Calculate final accuracy as percentage\n",
    "accuracy = (correct_predictions / total_predictions) * 100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving your model\n",
    "\n",
    "Once your model is done training, try tweaking your hyperparameters and training again below to improve your accuracy on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-12-4eba02ccdaaf>, line 63)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-4eba02ccdaaf>\"\u001b[0;36m, line \u001b[0;32m63\u001b[0m\n\u001b[0;31m    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Accuracy: {accuracy:.2f}%\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = eta\n",
    "num_epochs = 30\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "\n",
    "# Model definition and device placement\n",
    "model = Net().to(device)\n",
    "\n",
    "# Loss function (consider alternatives)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer with learning rate control\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Data loaders with efficiency tweaks\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):  # Renamed for clarity\n",
    "        # Move data to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Backward pass and update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track loss\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Print loss (optional)\n",
    "        if (batch_idx + 1) % print_loss_every == 0:\n",
    "            avg_loss = epoch_loss / print_loss_every\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {avg_loss:.4f}\")\n",
    "            train_loss_values.append(avg_loss)\n",
    "            epoch_loss = 0.0\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_correct, total_samples = 0, 0\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            predicted = torch.argmax(output, dim=1)  # Concise prediction\n",
    "\n",
    "            total_correct += (predicted == target).sum().item()\n",
    "            total_samples += target.size(0)\n",
    "\n",
    "        accuracy = (correct_predictions / total_predictions) * 100\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Accuracy: {accuracy:.2f}%\")\n",
    "    model.train()    \n",
    "    \n",
    "# Evaluate the model on the test set (model won't update weights)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_predictions = 0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for labels, images in test_loader:  # Load labels then images\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Get the predicted class\n",
    "        \n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "    \n",
    "    accuracy = (correct_predictions / total_predictions) * 100\n",
    "    print(f\"Final Test Accuracy: {accuracy:.2f}%\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving your model\n",
    "Using `torch.save`, save your model for future loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The path of our code file\n",
    "code_file_path = os.path.abspath(\"MNIST_Handwritten_Digits-STARTER.ipynb\")\n",
    "\n",
    "# The directory path of your code file\n",
    "code_directory = os.path.dirname(code_file_path)\n",
    "\n",
    "# Defining now the file path for saving the model\n",
    "model_path = os.path.join(code_directory, 'model.pth')\n",
    "\n",
    "# Finally, saving our model\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
